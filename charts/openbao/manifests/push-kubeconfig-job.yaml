# ──────────────────────────────────────────────────────────────────────────────
# push-kubeconfig-job.yaml — Copies kubeconfig from master node into OpenBao
#
# DECISION: Use a Kubernetes Job to push kubeconfig into OpenBao.
# Why: After OpenBao is running, the kubeconfig needs to be stored in it
#      so operators can retrieve it via the bootstrap token without SSH.
#      A Job running inside the cluster can read the kubeconfig from the
#      master node (via hostPath) and push it to OpenBao via the internal
#      ClusterIP service — no external network access needed.
#
# SECURITY:
#   - Job runs with a hostPath mount (read-only) to /etc/rancher/rke2/rke2.yaml
#   - Job must be scheduled on a master node (nodeSelector + toleration)
#   - Uses the bootstrap token to authenticate to OpenBao (one-time operation)
#   - Job auto-cleans after 5 minutes (ttlSecondsAfterFinished)
#
# USAGE:
#   This manifest is applied by the Helmfile postsync hook.
#   The OPENBAO_BOOTSTRAP_TOKEN placeholder must be replaced before applying.
#
# NOTE: This Job reads the RAW kubeconfig with 127.0.0.1 as the server.
#       The operator should use `tofu output -raw kube_config` for the
#       version with the LB IP already substituted. This Job exists as a
#       secondary/DR channel — the primary kubeconfig is in Terraform output.
# ──────────────────────────────────────────────────────────────────────────────
apiVersion: batch/v1
kind: Job
metadata:
  name: openbao-push-kubeconfig
  namespace: openbao
  labels:
    app.kubernetes.io/component: bootstrap
    app.kubernetes.io/part-of: openbao
  annotations:
    # NOTE: Job description for operator visibility.
    description: "One-time job to push kubeconfig from master node into OpenBao KV store"
spec:
  # SECURITY: Auto-delete after 5 minutes to avoid leaving the kubeconfig
  # mounted longer than necessary.
  ttlSecondsAfterFinished: 300
  backoffLimit: 3
  template:
    metadata:
      labels:
        app.kubernetes.io/component: bootstrap
        app.kubernetes.io/part-of: openbao
    spec:
      restartPolicy: OnFailure

      # DECISION: Schedule on master node to access kubeconfig.
      # Why: /etc/rancher/rke2/rke2.yaml only exists on control-plane nodes.
      nodeSelector:
        node-role.kubernetes.io/master: "true"

      # DECISION: Tolerate master taints to schedule on control-plane.
      # Why: Master nodes have taints that prevent regular workloads.
      tolerations:
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
        - key: node-role.kubernetes.io/control-plane
          effect: NoSchedule
        # WORKAROUND: HCCM uninitialized taint may still be present during
        # early bootstrap if this Job runs before HCCM finishes processing.
        - key: node.cloudprovider.kubernetes.io/uninitialized
          effect: NoSchedule

      containers:
        - name: push-kubeconfig
          image: alpine:3.19
          command:
            - /bin/sh
            - -c
            - |
              set -eu

              echo "=== OpenBao kubeconfig push ==="

              # Install curl for OpenBao API access
              apk add --no-cache curl >/dev/null 2>&1

              # Read kubeconfig from master node (mounted read-only)
              KUBECONFIG_CONTENT=$(cat /host-kubeconfig/rke2.yaml)

              if [ -z "$KUBECONFIG_CONTENT" ]; then
                echo "ERROR: kubeconfig is empty"
                exit 1
              fi

              # Wait for OpenBao to be ready
              echo "Waiting for OpenBao to be ready..."
              for i in $(seq 1 30); do
                if curl -sf http://openbao.openbao.svc.cluster.local:8200/v1/sys/health >/dev/null 2>&1; then
                  echo "OpenBao is ready"
                  break
                fi
                if [ "$i" -eq 30 ]; then
                  echo "ERROR: OpenBao did not become ready in 150s"
                  exit 1
                fi
                sleep 5
              done

              # Push kubeconfig to OpenBao KV store
              # NOTE: KV v2 is the default engine in dev mode at secret/
              echo "Pushing kubeconfig to OpenBao..."
              HTTP_CODE=$(curl -sf -o /dev/null -w "%{http_code}" \
                -X POST \
                -H "X-Vault-Token: ${OPENBAO_TOKEN}" \
                -H "Content-Type: application/json" \
                -d "{\"data\":{\"kubeconfig\":$(echo "$KUBECONFIG_CONTENT" | python3 -c 'import sys,json; print(json.dumps(sys.stdin.read()))' 2>/dev/null || echo "$KUBECONFIG_CONTENT" | sed 's/\\/\\\\/g; s/"/\\"/g; s/$/\\n/' | tr -d '\n' | sed 's/^/"/; s/\\n$/"/; s/\\n/\\n/g')}}" \
                "http://openbao.openbao.svc.cluster.local:8200/v1/secret/data/cluster/kubeconfig")

              if [ "$HTTP_CODE" = "200" ] || [ "$HTTP_CODE" = "204" ]; then
                echo "SUCCESS: kubeconfig stored at secret/cluster/kubeconfig"
              else
                echo "ERROR: OpenBao returned HTTP $HTTP_CODE"
                exit 1
              fi

              echo "=== Done ==="
          env:
            # SECURITY: Token injected from K8s Secret (not hardcoded in manifest).
            # The Secret is created by the presync hook (bootstrap-token-secret.yaml).
            - name: OPENBAO_TOKEN
              valueFrom:
                secretKeyRef:
                  name: openbao-bootstrap-token
                  key: token
          volumeMounts:
            # SECURITY: Read-only mount of the kubeconfig from the host.
            - name: host-kubeconfig
              mountPath: /host-kubeconfig
              readOnly: true
          resources:
            requests:
              memory: 32Mi
              cpu: 10m
            limits:
              memory: 64Mi
              cpu: 100m

      volumes:
        # DECISION: hostPath mount for kubeconfig.
        # Why: The kubeconfig exists only on master node filesystem.
        #      This is the simplest way to access it from within K8s.
        # SECURITY: Read-only, limited to the specific file path.
        - name: host-kubeconfig
          hostPath:
            path: /etc/rancher/rke2
            type: Directory
