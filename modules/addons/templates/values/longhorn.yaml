# ──────────────────────────────────────────────────────────────────────────────
# Longhorn Helm values — production-tuned for Open edX on Hetzner
# See: docs/PLAN-operational-readiness.md — Appendix A for tuning rationale
# ──────────────────────────────────────────────────────────────────────────────

defaultSettings:
  # --- Storage ---
  defaultReplicaCount: ${REPLICA_COUNT}
  # DECISION: Workers-only for data replicas. Protects master disk/etcd.
  # Longhorn manager DaemonSet still runs on masters (for orchestration),
  # but no data is stored on master nodes.
  # NOTE: This label is applied by kubernetes_labels.longhorn_worker in longhorn.tf.
  # RKE2 does NOT auto-label workers (only masters get role labels).
  # The label is set declaratively via kubernetes_labels after nodes join the cluster.
  systemManagedComponentsNodeSelector: "node-role.kubernetes.io/worker:true"
  # WORKAROUND: Allow Longhorn to create a default disk on each node automatically.
  # Why: With createDefaultDiskLabeledNodes=true, Longhorn only creates disks on nodes
  #      that carry the Longhorn-specific "create default disk" label. In fresh clusters
  #      (like this module's bootstrap flow) that label is not present, resulting in
  #      zero disks, faulted volumes, and PVC attach failures.
  #      Disabling it yields a working default out of the box.
  createDefaultDiskLabeledNodes: false

  # --- Backup ---
  backupTarget: "${BACKUP_TARGET}"
  backupTargetCredentialSecret: "${BACKUP_TARGET_CREDENTIAL_SECRET}"

  # --- Tuning (see Appendix A of PLAN-operational-readiness.md) ---
  # DECISION: Keep one replica local to the pod to avoid cross-DC network latency.
  # Why: In a multi-DC setup, synchronous writes across DCs add ~25ms latency.
  #      best-effort ensures the pod reads/writes locally if possible.
  defaultDataLocality: "best-effort"
  # DECISION: Disable revision counter to halve disk I/O.
  # Why: Revision counters cause double writes (data + metadata) for every fsync.
  #      Disabling it significantly improves IOPS for sync-heavy workloads like MySQL.
  disableRevisionCounter: "true"
  # DECISION: Auto-balance replicas to maintain HA across nodes.
  # Why: Works with dataLocality to ensure replicas are distributed evenly.
  replicaAutoBalance: "best-effort"
  # DECISION: Reserve CPU for instance managers to prevent starvation under load.
  # Default 12% per node. Prevents MySQL I/O stalls during Longhorn replica rebuild.
  guaranteedInstanceManagerCPU: ${GUARANTEED_INSTANCE_MANAGER_CPU}
  # DECISION: No overprovisioning. Hetzner NVMe is finite, no thin provisioning tricks.
  storageOverProvisioningPercentage: ${STORAGE_OVER_PROVISIONING}
  # DECISION: 15% minimum free disk. Alert threshold before Longhorn stops scheduling.
  storageMinimalAvailablePercentage: ${STORAGE_MINIMAL_AVAILABLE}
  # DECISION: Max 5 snapshots per volume. Prevents local disk fill from snapshot chains.
  snapshotMaxCount: ${SNAPSHOT_MAX_COUNT}
  # Auto-delete old snapshots when max is reached
  autoCleanupSnapshotWhenDeleteBackup: true

  # --- Resilience ---
  # DECISION: Auto-salvage replicas after unexpected detachment (node reboot, OOM kill).
  # Without this, volumes stay faulted and require manual intervention.
  autoSalvage: true
  # DECISION: Node drain policy — allow pod eviction during drain, Longhorn handles
  # replica rebuild automatically. Required for rolling upgrades.
  nodeDrainPolicy: "allow-if-replica-is-stopped"
  # DECISION: Concurrent replica rebuild limit per node. Prevents network saturation
  # during multiple volume recovery. Default 5 is too aggressive for shared 10Gbit NIC.
  concurrentReplicaRebuildPerNodeLimit: 3

persistence:
  defaultClass: ${DEFAULT_STORAGE_CLASS}
  defaultClassReplicaCount: ${REPLICA_COUNT}
  reclaimPolicy: Retain
  defaultDataLocality: "best-effort"
  disableRevisionCounter: "true"

longhornUI:
  # DECISION: Enable UI for operational visibility. Access via kubectl port-forward
  # or Ingress (not exposed by default — operator must configure access).
  enabled: true

# --- Recurring Jobs (backup schedule) ---
# DECISION: Default recurring job for all volumes — snapshot + backup to S3.
# Every volume tagged "default" gets automatic backup.
# RecurringJob runs at the same schedule as etcd backup for synchronized RPO.
%{ if BACKUP_TARGET != "" }
recurringJobSelector:
  - name: "backup-all"
    isGroup: true

longhornRecurringJobs:
  - name: "snapshot-and-backup"
    task: "backup"
    cron: "${BACKUP_SCHEDULE}"
    retain: ${BACKUP_RETAIN}
    concurrency: 2
    labels:
      recurring-job-group.longhorn.io/default: "enabled"
%{ endif }
